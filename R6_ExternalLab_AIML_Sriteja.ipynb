{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "### A MNIST-like fashion product database\n",
    "\n",
    "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "doRRn93l0fZB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efNjNImfOIUC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l9C4aAIGOIUH",
    "outputId": "6e9a078a-7100-49f7-a975-5d9d9510e0ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ"
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA1WsFSeOIUS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "qnbx7TyQOIUY",
    "outputId": "32447d12-c8b1-49a2-aafa-2c19b0a38207"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UbiHj5YPOIUc",
    "outputId": "5a89aa4f-1625-427c-ed68-8c8c86fe8f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "print(testY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "97k6f7x30yT6",
    "outputId": "1ce295fb-adf0-44ce-dfc4-9696d0d5f537"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o_eLrdPH02kp",
    "outputId": "288eecad-8b9d-44d3-d071-d1d2253959ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TLbaLWTq06yC",
    "outputId": "1df92579-4944-4677-8f41-1bdcc5c132b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "emI_Nuj40-_u",
    "outputId": "27c976df-0d2a-4a90-8c90-6ea6339452e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDAYzkwyOIUj"
   },
   "source": [
    "### Convert both training and testing labels into one-hot vectors.\n",
    "\n",
    "**Hint:** check **tf.keras.utils.to_categorical()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBlfYlANOIUk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "trainX = trainX.astype(np.float32)\n",
    "trainY = trainY.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNwsnZ1F1RvI"
   },
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "RHV3b9mzOIUq",
    "outputId": "8ba05c5c-b1ab-4885-8be1-ef822eaa664f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print('First 5 examples now are: ', trainY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwhQ8e7VOIUw"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot first 10 images in the triaining set and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "AvDML2OoOIUx",
    "outputId": "62b17c54-fa2d-479c-94d5-a99b739494b3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL for each of the image  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(trainX[i], cmap=plt.cm.binary)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('LABEL for each of the image ', trainY[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4TbJGeSOIU4"
   },
   "source": [
    "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac06XZZTOIU6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Comile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQpLv3aOIU_"
   },
   "source": [
    "### Execute the model using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "O59C_-IgOIVB",
    "outputId": "ad861a97-b42a-45f6-dd7b-0f78c02de8f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 9s 148us/sample - loss: 3.0643 - acc: 0.0942 - val_loss: 12.7705 - val_acc: 0.1059\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 9s 151us/sample - loss: 2.7795 - acc: 0.1266 - val_loss: 11.3018 - val_acc: 0.1136\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 2.5413 - acc: 0.1612 - val_loss: 9.9016 - val_acc: 0.1228\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.3421 - acc: 0.1982 - val_loss: 8.5796 - val_acc: 0.1368\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 2.1756 - acc: 0.2401 - val_loss: 7.3796 - val_acc: 0.1561\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.0364 - acc: 0.2806 - val_loss: 6.3426 - val_acc: 0.1739\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1.9196 - acc: 0.3160 - val_loss: 5.4841 - val_acc: 0.1970\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.8210 - acc: 0.3469 - val_loss: 4.8022 - val_acc: 0.2210\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.7373 - acc: 0.3746 - val_loss: 4.2648 - val_acc: 0.2465\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.6654 - acc: 0.4008 - val_loss: 3.8390 - val_acc: 0.2735\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.6033 - acc: 0.4267 - val_loss: 3.4970 - val_acc: 0.3000\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.5490 - acc: 0.4512 - val_loss: 3.2186 - val_acc: 0.3240\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.5012 - acc: 0.4748 - val_loss: 2.9888 - val_acc: 0.3492\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.4587 - acc: 0.4954 - val_loss: 2.7969 - val_acc: 0.3740\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.4207 - acc: 0.5138 - val_loss: 2.6342 - val_acc: 0.3985\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.3864 - acc: 0.5304 - val_loss: 2.4946 - val_acc: 0.4188\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.3553 - acc: 0.5436 - val_loss: 2.3738 - val_acc: 0.4377\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.3268 - acc: 0.5552 - val_loss: 2.2679 - val_acc: 0.4565\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.3007 - acc: 0.5652 - val_loss: 2.1743 - val_acc: 0.4752\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 1.2766 - acc: 0.5739 - val_loss: 2.0912 - val_acc: 0.4919\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 1.2542 - acc: 0.5824 - val_loss: 2.0169 - val_acc: 0.5076\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.2333 - acc: 0.5896 - val_loss: 1.9501 - val_acc: 0.5211\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.2139 - acc: 0.5966 - val_loss: 1.8897 - val_acc: 0.5315\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.1956 - acc: 0.6033 - val_loss: 1.8347 - val_acc: 0.5424\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.1785 - acc: 0.6097 - val_loss: 1.7843 - val_acc: 0.5537\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.1623 - acc: 0.6149 - val_loss: 1.7379 - val_acc: 0.5624\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.1470 - acc: 0.6197 - val_loss: 1.6952 - val_acc: 0.5706\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.1326 - acc: 0.6243 - val_loss: 1.6556 - val_acc: 0.5786\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.1189 - acc: 0.6286 - val_loss: 1.6187 - val_acc: 0.5871\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.1059 - acc: 0.6330 - val_loss: 1.5843 - val_acc: 0.5940\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.0935 - acc: 0.6372 - val_loss: 1.5521 - val_acc: 0.5987\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.0817 - acc: 0.6412 - val_loss: 1.5219 - val_acc: 0.6045\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 1.0704 - acc: 0.6442 - val_loss: 1.4935 - val_acc: 0.6085\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.0596 - acc: 0.6473 - val_loss: 1.4667 - val_acc: 0.6119\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1.0493 - acc: 0.6508 - val_loss: 1.4414 - val_acc: 0.6154\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.0395 - acc: 0.6538 - val_loss: 1.4175 - val_acc: 0.6184\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.0300 - acc: 0.6569 - val_loss: 1.3947 - val_acc: 0.6215\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.0209 - acc: 0.6597 - val_loss: 1.3732 - val_acc: 0.6249\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.0122 - acc: 0.6624 - val_loss: 1.3526 - val_acc: 0.6278\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 1.0038 - acc: 0.6647 - val_loss: 1.3330 - val_acc: 0.6314\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.9957 - acc: 0.6672 - val_loss: 1.3142 - val_acc: 0.6346\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.9879 - acc: 0.6696 - val_loss: 1.2963 - val_acc: 0.6371\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.9803 - acc: 0.6716 - val_loss: 1.2792 - val_acc: 0.6390\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.9731 - acc: 0.6741 - val_loss: 1.2627 - val_acc: 0.6413\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.9660 - acc: 0.6763 - val_loss: 1.2470 - val_acc: 0.6436\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.9593 - acc: 0.6783 - val_loss: 1.2319 - val_acc: 0.6456\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.9527 - acc: 0.6801 - val_loss: 1.2174 - val_acc: 0.6472\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.9463 - acc: 0.6817 - val_loss: 1.2034 - val_acc: 0.6488\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.9402 - acc: 0.6834 - val_loss: 1.1900 - val_acc: 0.6517\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.9342 - acc: 0.6849 - val_loss: 1.1770 - val_acc: 0.6536\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.9285 - acc: 0.6865 - val_loss: 1.1645 - val_acc: 0.6548\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.9228 - acc: 0.6879 - val_loss: 1.1525 - val_acc: 0.6566\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.9174 - acc: 0.6891 - val_loss: 1.1408 - val_acc: 0.6577\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.9121 - acc: 0.6909 - val_loss: 1.1296 - val_acc: 0.6593\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.9070 - acc: 0.6924 - val_loss: 1.1187 - val_acc: 0.6612\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.9020 - acc: 0.6939 - val_loss: 1.1082 - val_acc: 0.6632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.8971 - acc: 0.6953 - val_loss: 1.0981 - val_acc: 0.6652\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.8924 - acc: 0.6969 - val_loss: 1.0882 - val_acc: 0.6672\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8878 - acc: 0.6980 - val_loss: 1.0787 - val_acc: 0.6688\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8833 - acc: 0.6994 - val_loss: 1.0694 - val_acc: 0.6708\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8789 - acc: 0.7006 - val_loss: 1.0605 - val_acc: 0.6719\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8747 - acc: 0.7018 - val_loss: 1.0518 - val_acc: 0.6731\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8705 - acc: 0.7029 - val_loss: 1.0433 - val_acc: 0.6748\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8665 - acc: 0.7037 - val_loss: 1.0351 - val_acc: 0.6760\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8625 - acc: 0.7050 - val_loss: 1.0271 - val_acc: 0.6767\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8587 - acc: 0.7061 - val_loss: 1.0194 - val_acc: 0.6785\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.8549 - acc: 0.7071 - val_loss: 1.0119 - val_acc: 0.6796\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8512 - acc: 0.7084 - val_loss: 1.0045 - val_acc: 0.6814\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.8476 - acc: 0.7096 - val_loss: 0.9974 - val_acc: 0.6837\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8441 - acc: 0.7106 - val_loss: 0.9904 - val_acc: 0.6854\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.8407 - acc: 0.7116 - val_loss: 0.9837 - val_acc: 0.6879\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.8373 - acc: 0.7126 - val_loss: 0.9771 - val_acc: 0.6887\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8340 - acc: 0.7136 - val_loss: 0.9707 - val_acc: 0.6900\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.8308 - acc: 0.7148 - val_loss: 0.9644 - val_acc: 0.6904\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8277 - acc: 0.7160 - val_loss: 0.9584 - val_acc: 0.6909\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8246 - acc: 0.7169 - val_loss: 0.9524 - val_acc: 0.6921\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.8216 - acc: 0.7181 - val_loss: 0.9466 - val_acc: 0.6929\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8186 - acc: 0.7192 - val_loss: 0.9410 - val_acc: 0.6948\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8157 - acc: 0.7201 - val_loss: 0.9355 - val_acc: 0.6966\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8129 - acc: 0.7209 - val_loss: 0.9301 - val_acc: 0.6975\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.8101 - acc: 0.7222 - val_loss: 0.9249 - val_acc: 0.6985\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.8074 - acc: 0.7232 - val_loss: 0.9197 - val_acc: 0.6998\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.8047 - acc: 0.7240 - val_loss: 0.9147 - val_acc: 0.7012\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.8021 - acc: 0.7247 - val_loss: 0.9098 - val_acc: 0.7018\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.7995 - acc: 0.7255 - val_loss: 0.9051 - val_acc: 0.7030\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.7969 - acc: 0.7266 - val_loss: 0.9004 - val_acc: 0.7038\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.7945 - acc: 0.7274 - val_loss: 0.8958 - val_acc: 0.7050\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.7920 - acc: 0.7283 - val_loss: 0.8914 - val_acc: 0.7070\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.7896 - acc: 0.7291 - val_loss: 0.8870 - val_acc: 0.7074\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.7873 - acc: 0.7298 - val_loss: 0.8828 - val_acc: 0.7083\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.7850 - acc: 0.7305 - val_loss: 0.8786 - val_acc: 0.7099\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.7827 - acc: 0.7313 - val_loss: 0.8745 - val_acc: 0.7109\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.7804 - acc: 0.7321 - val_loss: 0.8705 - val_acc: 0.7117\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.7782 - acc: 0.7328 - val_loss: 0.8666 - val_acc: 0.7127\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.7761 - acc: 0.7336 - val_loss: 0.8628 - val_acc: 0.7140\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.7740 - acc: 0.7343 - val_loss: 0.8591 - val_acc: 0.7147\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.7719 - acc: 0.7351 - val_loss: 0.8554 - val_acc: 0.7160\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.7698 - acc: 0.7358 - val_loss: 0.8518 - val_acc: 0.7165\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.7678 - acc: 0.7363 - val_loss: 0.8483 - val_acc: 0.7176\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.7658 - acc: 0.7371 - val_loss: 0.8449 - val_acc: 0.7188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18ca0533cf8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, \n",
    "          validation_data=(testX, testY), \n",
    "          epochs=100,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6Euk01q8Jhf"
   },
   "outputs": [],
   "source": [
    "#model Accuracy Improved from 13% to 72%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdzDtGwDOIVF"
   },
   "source": [
    "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kndfpdidOIVI"
   },
   "outputs": [],
   "source": [
    "##Batch Normalization used in the above step only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwk3T5LJOIVN"
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "JNLR8tcBOIVP",
    "outputId": "f29cfd87-368e-4415-cdc7-606fb45ef1ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 10,986\n",
      "Trainable params: 9,418\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-KwkmjOIVU"
   },
   "source": [
    "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yLXUE9jWOIVV",
    "outputId": "e3bfd2f3-abc6-4972-fc90-6c1e5b3247ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7552 - acc: 0.7449 - val_loss: 0.8329 - val_acc: 0.7249\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7535 - acc: 0.7455 - val_loss: 0.8298 - val_acc: 0.7253\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7517 - acc: 0.7461 - val_loss: 0.8268 - val_acc: 0.7262\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7500 - acc: 0.7467 - val_loss: 0.8239 - val_acc: 0.7275\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7483 - acc: 0.7472 - val_loss: 0.8210 - val_acc: 0.7283\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7466 - acc: 0.7477 - val_loss: 0.8182 - val_acc: 0.7287\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7450 - acc: 0.7483 - val_loss: 0.8154 - val_acc: 0.7292\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7434 - acc: 0.7487 - val_loss: 0.8127 - val_acc: 0.7298\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7417 - acc: 0.7490 - val_loss: 0.8100 - val_acc: 0.7302\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7402 - acc: 0.7495 - val_loss: 0.8074 - val_acc: 0.7308\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7386 - acc: 0.7499 - val_loss: 0.8048 - val_acc: 0.7316\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7370 - acc: 0.7505 - val_loss: 0.8023 - val_acc: 0.7325\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7355 - acc: 0.7509 - val_loss: 0.7998 - val_acc: 0.7331\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7340 - acc: 0.7514 - val_loss: 0.7973 - val_acc: 0.7336\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7325 - acc: 0.7521 - val_loss: 0.7949 - val_acc: 0.7336\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7311 - acc: 0.7525 - val_loss: 0.7926 - val_acc: 0.7343\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7296 - acc: 0.7530 - val_loss: 0.7903 - val_acc: 0.7351\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7282 - acc: 0.7536 - val_loss: 0.7880 - val_acc: 0.7356\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7268 - acc: 0.7539 - val_loss: 0.7858 - val_acc: 0.7360\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7253 - acc: 0.7546 - val_loss: 0.7836 - val_acc: 0.7361\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7240 - acc: 0.7549 - val_loss: 0.7814 - val_acc: 0.7366\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7226 - acc: 0.7554 - val_loss: 0.7793 - val_acc: 0.7368\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7212 - acc: 0.7560 - val_loss: 0.7772 - val_acc: 0.7379\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7199 - acc: 0.7565 - val_loss: 0.7752 - val_acc: 0.7384\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7186 - acc: 0.7571 - val_loss: 0.7732 - val_acc: 0.7383\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7173 - acc: 0.7574 - val_loss: 0.7712 - val_acc: 0.7389\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7160 - acc: 0.7580 - val_loss: 0.7692 - val_acc: 0.7396\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7147 - acc: 0.7586 - val_loss: 0.7673 - val_acc: 0.7400\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7134 - acc: 0.7590 - val_loss: 0.7654 - val_acc: 0.7410\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7122 - acc: 0.7593 - val_loss: 0.7636 - val_acc: 0.7414\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7110 - acc: 0.7598 - val_loss: 0.7617 - val_acc: 0.7415\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7097 - acc: 0.7602 - val_loss: 0.7599 - val_acc: 0.7416\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7085 - acc: 0.7605 - val_loss: 0.7582 - val_acc: 0.7419\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7073 - acc: 0.7608 - val_loss: 0.7564 - val_acc: 0.7420\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7061 - acc: 0.7610 - val_loss: 0.7547 - val_acc: 0.7424\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7050 - acc: 0.7614 - val_loss: 0.7530 - val_acc: 0.7424\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7038 - acc: 0.7617 - val_loss: 0.7514 - val_acc: 0.7428\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7027 - acc: 0.7620 - val_loss: 0.7497 - val_acc: 0.7435\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7015 - acc: 0.7624 - val_loss: 0.7481 - val_acc: 0.7443\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7004 - acc: 0.7629 - val_loss: 0.7465 - val_acc: 0.7446\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6993 - acc: 0.7633 - val_loss: 0.7450 - val_acc: 0.7450\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6982 - acc: 0.7636 - val_loss: 0.7434 - val_acc: 0.7455\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6971 - acc: 0.7639 - val_loss: 0.7419 - val_acc: 0.7458\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6960 - acc: 0.7642 - val_loss: 0.7404 - val_acc: 0.7458\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6949 - acc: 0.7646 - val_loss: 0.7389 - val_acc: 0.7467\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6939 - acc: 0.7652 - val_loss: 0.7375 - val_acc: 0.7471\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.6928 - acc: 0.7655 - val_loss: 0.7361 - val_acc: 0.7474\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6918 - acc: 0.7659 - val_loss: 0.7347 - val_acc: 0.7473\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.6908 - acc: 0.7660 - val_loss: 0.7333 - val_acc: 0.7475\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6897 - acc: 0.7664 - val_loss: 0.7319 - val_acc: 0.7481\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6887 - acc: 0.7666 - val_loss: 0.7305 - val_acc: 0.7486\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6877 - acc: 0.7669 - val_loss: 0.7292 - val_acc: 0.7491\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.6867 - acc: 0.7672 - val_loss: 0.7279 - val_acc: 0.7497\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6857 - acc: 0.7675 - val_loss: 0.7266 - val_acc: 0.7502\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.6848 - acc: 0.7678 - val_loss: 0.7253 - val_acc: 0.7507\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6838 - acc: 0.7681 - val_loss: 0.7241 - val_acc: 0.7513\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.6828 - acc: 0.7685 - val_loss: 0.7228 - val_acc: 0.7521\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6819 - acc: 0.7688 - val_loss: 0.7216 - val_acc: 0.7525\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6810 - acc: 0.7690 - val_loss: 0.7204 - val_acc: 0.7527\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6800 - acc: 0.7692 - val_loss: 0.7192 - val_acc: 0.7527\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6791 - acc: 0.7695 - val_loss: 0.7180 - val_acc: 0.7532\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6782 - acc: 0.7699 - val_loss: 0.7169 - val_acc: 0.7538\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.6773 - acc: 0.7702 - val_loss: 0.7157 - val_acc: 0.7540\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6764 - acc: 0.7704 - val_loss: 0.7146 - val_acc: 0.7547\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.6755 - acc: 0.7707 - val_loss: 0.7135 - val_acc: 0.7552\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6746 - acc: 0.7710 - val_loss: 0.7124 - val_acc: 0.7553\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.6737 - acc: 0.7712 - val_loss: 0.7113 - val_acc: 0.7551\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.6728 - acc: 0.7715 - val_loss: 0.7102 - val_acc: 0.7552\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6720 - acc: 0.7718 - val_loss: 0.7091 - val_acc: 0.7555\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6711 - acc: 0.7721 - val_loss: 0.7081 - val_acc: 0.7554\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6703 - acc: 0.7722 - val_loss: 0.7070 - val_acc: 0.7557\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6694 - acc: 0.7725 - val_loss: 0.7060 - val_acc: 0.7561\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6686 - acc: 0.7728 - val_loss: 0.7050 - val_acc: 0.7564\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6678 - acc: 0.7730 - val_loss: 0.7040 - val_acc: 0.7565\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.6670 - acc: 0.7734 - val_loss: 0.7030 - val_acc: 0.7568\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6661 - acc: 0.7735 - val_loss: 0.7020 - val_acc: 0.7572\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6653 - acc: 0.7739 - val_loss: 0.7011 - val_acc: 0.7576\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6645 - acc: 0.7740 - val_loss: 0.7001 - val_acc: 0.7583\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6637 - acc: 0.7743 - val_loss: 0.6992 - val_acc: 0.7587\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6629 - acc: 0.7746 - val_loss: 0.6982 - val_acc: 0.7593\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6622 - acc: 0.7748 - val_loss: 0.6973 - val_acc: 0.7592\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6614 - acc: 0.7751 - val_loss: 0.6964 - val_acc: 0.7599\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6606 - acc: 0.7754 - val_loss: 0.6955 - val_acc: 0.7603\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6599 - acc: 0.7757 - val_loss: 0.6946 - val_acc: 0.7607\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6591 - acc: 0.7760 - val_loss: 0.6937 - val_acc: 0.7612\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6583 - acc: 0.7762 - val_loss: 0.6929 - val_acc: 0.7614\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.6576 - acc: 0.7764 - val_loss: 0.6920 - val_acc: 0.7615\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6569 - acc: 0.7766 - val_loss: 0.6911 - val_acc: 0.7618\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.6561 - acc: 0.7769 - val_loss: 0.6903 - val_acc: 0.7623\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6554 - acc: 0.7772 - val_loss: 0.6895 - val_acc: 0.7627\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6547 - acc: 0.7774 - val_loss: 0.6886 - val_acc: 0.7630\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6539 - acc: 0.7776 - val_loss: 0.6878 - val_acc: 0.7634\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6532 - acc: 0.7780 - val_loss: 0.6870 - val_acc: 0.7633\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6525 - acc: 0.7782 - val_loss: 0.6862 - val_acc: 0.7633\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6518 - acc: 0.7786 - val_loss: 0.6854 - val_acc: 0.7635\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6511 - acc: 0.7789 - val_loss: 0.6846 - val_acc: 0.7637\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6504 - acc: 0.7792 - val_loss: 0.6839 - val_acc: 0.7640\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6497 - acc: 0.7794 - val_loss: 0.6831 - val_acc: 0.7640\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6490 - acc: 0.7798 - val_loss: 0.6823 - val_acc: 0.7646\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6484 - acc: 0.7801 - val_loss: 0.6816 - val_acc: 0.7648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f58f37b8d68>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.01)\n",
    "\n",
    "model.fit(trainX, trainY, \n",
    "          validation_data=(testX, testY), \n",
    "          epochs=100,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJUqA5T4OIVc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CSqKvpOIVk"
   },
   "source": [
    "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hr8CH6OO6dYr"
   },
   "outputs": [],
   "source": [
    "\n",
    "trainX = trainX.astype('float32')\n",
    "trainY = trainY.astype('float32')\n",
    "\n",
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGAad54JOIVm"
   },
   "outputs": [],
   "source": [
    "#Add 1st hidden layer\n",
    "model.add(tf.keras.layers.Dense(200, activation='sigmoid'))\n",
    "\n",
    "#Add 2nd hidden layer\n",
    "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "\n",
    "#Add OUTPUT layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ7oIymROIVp"
   },
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "colab_type": "code",
    "id": "X-O-fFxnOIVt",
    "outputId": "c0ffe34e-566a-4b3f-c695-cb226229af51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 12s 204us/sample - loss: 1.4210 - acc: 0.6284 - val_loss: 0.9088 - val_acc: 0.7329\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.7870 - acc: 0.7462 - val_loss: 0.6865 - val_acc: 0.7630\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 11s 177us/sample - loss: 0.6537 - acc: 0.7716 - val_loss: 0.6063 - val_acc: 0.7816\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 11s 179us/sample - loss: 0.5888 - acc: 0.7920 - val_loss: 0.5573 - val_acc: 0.7995\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.5445 - acc: 0.8071 - val_loss: 0.5251 - val_acc: 0.8106\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 11s 177us/sample - loss: 0.5156 - acc: 0.8171 - val_loss: 0.5018 - val_acc: 0.8203\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 11s 178us/sample - loss: 0.4955 - acc: 0.8251 - val_loss: 0.4863 - val_acc: 0.8263\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 11s 179us/sample - loss: 0.4770 - acc: 0.8297 - val_loss: 0.4727 - val_acc: 0.8300\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.4624 - acc: 0.8359 - val_loss: 0.4624 - val_acc: 0.8344\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 11s 184us/sample - loss: 0.4531 - acc: 0.8384 - val_loss: 0.4538 - val_acc: 0.8356\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.4447 - acc: 0.8429 - val_loss: 0.4459 - val_acc: 0.8387\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.4362 - acc: 0.8446 - val_loss: 0.4401 - val_acc: 0.8406\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 12s 195us/sample - loss: 0.4278 - acc: 0.8477 - val_loss: 0.4342 - val_acc: 0.8429\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 11s 184us/sample - loss: 0.4220 - acc: 0.8499 - val_loss: 0.4300 - val_acc: 0.8444\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 11s 184us/sample - loss: 0.4176 - acc: 0.8519 - val_loss: 0.4239 - val_acc: 0.8467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18ca583e320>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX,trainY,          \n",
    "          validation_data=(testX,testY),\n",
    "          epochs=15,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiP7IL52OIVw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2YsZV0OIV0"
   },
   "source": [
    "## Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4ojW6-oOIV2"
   },
   "outputs": [],
   "source": [
    "##As Per the Model the Accuracy reached  from 73% to  84% and Loss reduced from 0.90 to 0.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "pjSBb5bY7w7N",
    "outputId": "2f9d20e1-d8d7-47df-ea21-014430dc6c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 181,246\n",
      "Trainable params: 179,678\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfFGmbZLOIV5"
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bIkbMEN5OIV7"
   },
   "outputs": [],
   "source": [
    "##Saving the Model\n",
    "model.save('mnist_lc_v2.h2')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "R6_ExternalLab_AIML.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
